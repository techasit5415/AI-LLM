@echo off
chcp 65001 >nul
REM Alternative solution: Install CPU-only llama-cpp-python or use different approach
REM ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß: ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö CPU-only ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏≠‡∏∑‡πà‡∏ô

echo üîÑ Alternative llama-cpp-python Installation
echo ============================================

REM ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô virtual environment
call llm_rag_env\Scripts\activate.bat

echo üì¶ ‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á llama-cpp-python ‡∏à‡∏≤‡∏Å alternative sources...

REM Method 1: Try CPU-only pre-compiled wheel
echo üîç Method 1: CPU-only wheel from official repository...
pip install --prefer-binary llama-cpp-python --index-url https://pypi.org/simple/ --no-build-isolation
if not errorlevel 1 goto success

REM Method 2: Try older version that might have wheels
echo üîç Method 2: Older version with pre-compiled wheels...
pip install llama-cpp-python==0.1.83 --no-cache-dir
if not errorlevel 1 goto success

REM Method 3: Try alternative package (llamacpp-python)
echo üîç Method 3: Alternative package...
pip install llamacpp-python
if not errorlevel 1 goto alternative_success

REM Method 4: Use transformers + CPU instead
echo üîç Method 4: Fallback to transformers (will be slower)...
pip install transformers torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
if not errorlevel 1 goto transformers_success

echo ‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á llama-cpp-python ‡πÑ‡∏î‡πâ
echo üí° ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:
echo    1. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Visual Studio Community (‡∏°‡∏µ C++ compiler ‡∏Ñ‡∏£‡∏ö)
echo    2. ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ WSL2 + Ubuntu ‡∏ã‡∏∂‡πà‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏á‡πà‡∏≤‡∏¢‡∏Å‡∏ß‡πà‡∏≤
echo    3. ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ cloud services ‡πÄ‡∏ä‡πà‡∏ô Google Colab
goto end

:success
echo ‚úÖ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á llama-cpp-python ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!
echo üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô...
python -c "from llama_cpp import Llama; print('‚úÖ llama-cpp-python ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô')"
goto install_others

:alternative_success
echo ‚úÖ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á alternative package ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!
echo ‚ö†Ô∏è ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç import ‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î
goto install_others

:transformers_success
echo ‚úÖ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á transformers ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!
echo ‚ö†Ô∏è ‡∏à‡∏∞‡πÉ‡∏ä‡πâ transformers ‡πÅ‡∏ó‡∏ô llama-cpp-python (‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤‡πÅ‡∏ï‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ)
goto install_others

:install_others
echo üì¶ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á packages ‡∏≠‡∏∑‡πà‡∏ô‡πÜ...
pip install streamlit langchain langchain-community faiss-cpu sentence-transformers

echo.
echo üéâ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!
echo üìã ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ:
echo    1. ‡∏£‡∏±‡∏ô: streamlit run rag_chatbot.py
echo    2. ‡∏´‡∏≤‡∏Å‡∏°‡∏µ error ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö llama-cpp-python ‡πÉ‡∏´‡πâ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÇ‡∏Ñ‡πâ‡∏î‡πÉ‡∏ä‡πâ transformers ‡πÅ‡∏ó‡∏ô

:end
pause
