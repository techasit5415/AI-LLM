@echo off
chcp 65001 >nul
REM Alternative LLM Installation - ‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∑‡πà‡∏ô‡πÅ‡∏ó‡∏ô llama-cpp-python
REM ‡πÉ‡∏ä‡πâ Ollama ‡∏´‡∏£‡∏∑‡∏≠ Transformers ‡πÅ‡∏ó‡∏ô

echo üîÑ Alternative LLM Setup - ‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∑‡πà‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM
echo =================================================

REM ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô project directory
cd /d "%~dp0.."
if not exist "rag_chatbot.py" (
    echo ‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå rag_chatbot.py
    echo    ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤ cd ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô LLM-RAG directory ‡∏Å‡πà‡∏≠‡∏ô
    pause
    exit /b 1
)

echo.
echo üéØ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM:
echo.
echo 1Ô∏è‚É£  Ollama (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ - ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢)
echo     - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ compilation
echo     - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö GPU ‡πÅ‡∏•‡∏∞ CPU
echo     - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
echo.
echo 2Ô∏è‚É£  Transformers + PyTorch (‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£)
echo     - ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏à‡∏≤‡∏Å Hugging Face
echo     - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢
echo     - ‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢
echo.
echo 3Ô∏è‚É£  ‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å
echo.

set /p choice="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (1-3): "

if "%choice%"=="1" (
    goto :install_ollama
) else if "%choice%"=="2" (
    goto :install_transformers
) else if "%choice%"=="3" (
    echo üëã ‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á
    exit /b 0
) else (
    echo ‚ùå ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
    pause
    exit /b 1
)

:install_ollama
echo.
echo ü¶ô ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Ollama
echo ================

REM ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô virtual environment
if exist "llm_rag_env\Scripts\activate.bat" (
    echo üîÑ ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô virtual environment...
    call llm_rag_env\Scripts\activate.bat
) else (
    echo üì¶ ‡∏™‡∏£‡πâ‡∏≤‡∏á virtual environment...
    python -m venv llm_rag_env
    call llm_rag_env\Scripts\activate.bat
)

echo üì¶ ‡∏≠‡∏±‡∏û‡πÄ‡∏Å‡∏£‡∏î pip...
python -m pip install --upgrade pip

echo üîΩ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Ollama Windows client...
echo    ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Ollama...

REM ‡πÉ‡∏ä‡πâ winget ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Ollama
winget install Ollama.Ollama --accept-source-agreements --accept-package-agreements
if errorlevel 1 (
    echo ‚ö†Ô∏è winget ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏•‡∏≠‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡∏≠‡∏∑‡πà‡∏ô...
    echo.
    echo üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Ollama manual:
    echo    1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà: https://ollama.ai/download/windows
    echo    2. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Ollama for Windows
    echo    3. ‡∏£‡∏µ‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó command prompt
    echo    4. ‡∏£‡∏±‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ô‡∏µ‡πâ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
    pause
    exit /b 1
)

echo üì¶ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Python package ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Ollama...
pip install ollama requests

echo üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Ollama...
python -c "
try:
    import ollama
    print('‚úÖ Ollama Python client ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à')
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Ollama server
    try:
        response = ollama.list()
        print('‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Ollama server ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à')
        print('üìã ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ:', len(response.get('models', [])), '‡πÇ‡∏°‡πÄ‡∏î‡∏•')
    except Exception as e:
        print('‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Ollama server:', str(e))
        print('üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏° Ollama service ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏µ‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á')
        
except ImportError:
    print('‚ùå ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Ollama Python client ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à')
    exit(1)
"

if errorlevel 1 (
    goto :installation_failed
)

echo.
echo üì¶ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies ‡∏≠‡∏∑‡πà‡∏ô‡πÜ...
pip install streamlit langchain langchain-community faiss-cpu sentence-transformers

echo.
echo üéâ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Ollama ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!
echo =======================
echo.
echo üìã ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ:
echo 1. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•: ollama pull llama3.2:3b
echo 2. ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç rag_chatbot.py ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ Ollama ‡πÅ‡∏ó‡∏ô llama-cpp-python
echo 3. ‡∏£‡∏±‡∏ô: streamlit run rag_chatbot.py
echo.
echo üí° ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:
echo    ollama pull llama3.2:3b      (3GB)
echo    ollama pull llama3.1:8b      (4.7GB)
echo    ollama pull codellama:7b     (3.8GB)
echo.

goto :create_ollama_config

:install_transformers
echo.
echo ü§ó ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Transformers + PyTorch
echo ================================

REM ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô virtual environment
if exist "llm_rag_env\Scripts\activate.bat" (
    echo üîÑ ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô virtual environment...
    call llm_rag_env\Scripts\activate.bat
) else (
    echo üì¶ ‡∏™‡∏£‡πâ‡∏≤‡∏á virtual environment...
    python -m venv llm_rag_env
    call llm_rag_env\Scripts\activate.bat
)

echo üì¶ ‡∏≠‡∏±‡∏û‡πÄ‡∏Å‡∏£‡∏î pip...
python -m pip install --upgrade pip

echo üîΩ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyTorch (CPU version)...
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

echo ü§ó ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Transformers ‡πÅ‡∏•‡∏∞ dependencies...
pip install transformers accelerate

echo üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Transformers...
python -c "
try:
    import torch
    import transformers
    print('‚úÖ PyTorch version:', torch.__version__)
    print('‚úÖ Transformers version:', transformers.__version__)
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏•‡πá‡∏Å
    from transformers import pipeline
    print('üîÑ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏´‡∏•‡∏î text generation pipeline...')
    # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏•‡πá‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    generator = pipeline('text-generation', model='distilgpt2', max_length=10)
    result = generator('Hello', max_length=10, num_return_sequences=1)
    print('‚úÖ Text generation ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ!')
    
except Exception as e:
    print('‚ùå ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à:', str(e))
    exit(1)
"

if errorlevel 1 (
    goto :installation_failed
)

echo.
echo üì¶ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies ‡∏≠‡∏∑‡πà‡∏ô‡πÜ...
pip install streamlit langchain langchain-community faiss-cpu sentence-transformers

echo.
echo üéâ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Transformers ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!
echo ==============================
echo.
echo üìã ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ:
echo 1. ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç rag_chatbot.py ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ Transformers
echo 2. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å Hugging Face Hub
echo 3. ‡∏£‡∏±‡∏ô: streamlit run rag_chatbot.py
echo.
echo üí° ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:
echo    microsoft/DialoGPT-medium
echo    microsoft/DialoGPT-large
echo    gpt2
echo.

goto :create_transformers_config

:create_ollama_config
echo.
echo üìù ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå config ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Ollama...

echo # Ollama Configuration > ollama_config.py
echo model_name = "llama3.2:3b" >> ollama_config.py
echo base_url = "http://localhost:11434" >> ollama_config.py

echo ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á ollama_config.py ‡πÅ‡∏•‡πâ‡∏ß
goto :finish

:create_transformers_config
echo.
echo üìù ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå config ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Transformers...

echo # Transformers Configuration > transformers_config.py
echo model_name = "microsoft/DialoGPT-medium" >> transformers_config.py
echo device = "cpu" >> transformers_config.py

echo ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á transformers_config.py ‡πÅ‡∏•‡πâ‡∏ß
goto :finish

:finish
echo.
echo üîß ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÇ‡∏Ñ‡πâ‡∏î:
echo.
echo 1. ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç rag_chatbot.py
echo 2. ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å llama_cpp import
echo 3. ‡πÉ‡∏ä‡πâ Ollama ‡∏´‡∏£‡∏∑‡∏≠ Transformers ‡πÅ‡∏ó‡∏ô
echo.
echo üìñ ‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô:
echo    .\issue\LLAMA_CPP_PYTHON_TROUBLESHOOTING.md
echo.

pause
exit /b 0

:installation_failed
echo.
echo ‚ùå ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
echo ==================
echo.
echo üîß ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:
echo.
echo 1Ô∏è‚É£ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢
echo 2Ô∏è‚É£ ‡∏•‡∏≠‡∏á‡∏£‡∏±‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
echo 3Ô∏è‚É£ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á manual ‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå
echo 4Ô∏è‚É£ ‡πÉ‡∏ä‡πâ‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∑‡πà‡∏ô (cloud services)
echo.

pause
exit /b 1
