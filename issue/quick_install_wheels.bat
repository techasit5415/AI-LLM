@echo off
chcp 65001 >nul
REM Quick Install using pre-compiled wheels
REM ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πà‡∏ß‡∏ô‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ wheel ‡∏ó‡∏µ‡πà compile ‡πÅ‡∏•‡πâ‡∏ß

echo üöÄ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πà‡∏ß‡∏ô llama-cpp-python ‡πÅ‡∏ö‡∏ö Pre-compiled Wheel
echo =====================================================

REM ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô project directory
cd /d "%~dp0.."
if not exist "rag_chatbot.py" (
    echo ‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå rag_chatbot.py
    echo    ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤ cd ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô LLM-RAG directory ‡∏Å‡πà‡∏≠‡∏ô
    pause
    exit /b 1
)

REM ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô virtual environment
if exist "llm_rag_env\Scripts\activate.bat" (
    echo üîÑ ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô virtual environment...
    call llm_rag_env\Scripts\activate.bat
) else (
    echo ‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö virtual environment
    echo    ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô: python -m venv llm_rag_env
    pause
    exit /b 1
)

echo üóëÔ∏è ‡∏•‡∏ö llama-cpp-python ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏Å‡πà‡∏≤ (‡∏´‡∏≤‡∏Å‡∏°‡∏µ)...
pip uninstall llama-cpp-python -y >nul 2>&1

echo üì¶ ‡∏≠‡∏±‡∏û‡πÄ‡∏Å‡∏£‡∏î pip ‡πÅ‡∏•‡∏∞ tools...
python -m pip install --upgrade pip setuptools wheel

echo.
echo üéØ ‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏à‡∏≤‡∏Å Pre-compiled wheels ‡∏ï‡πà‡∏≤‡∏á‡πÜ...
echo.

REM Method 1: CPU wheel ‡∏à‡∏≤‡∏Å official repo
echo üîÑ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: CPU wheel ‡∏à‡∏≤‡∏Å abetlen/llama-cpp-python...
pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu --force-reinstall --no-cache-dir
if not errorlevel 1 (
    echo ‚úÖ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏à‡∏≤‡∏Å CPU wheel ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!
    goto :test_installation
)

echo ‚ùå ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1 ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à

REM Method 2: ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ wheels ‡∏à‡∏≤‡∏Å PyPI ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
echo.
echo üîÑ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡∏´‡∏≤ wheel ‡∏à‡∏≤‡∏Å PyPI...
pip install llama-cpp-python --only-binary=:all: --force-reinstall --no-cache-dir
if not errorlevel 1 (
    echo ‚úÖ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏à‡∏≤‡∏Å PyPI wheel ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!
    goto :test_installation
)

echo ‚ùå ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2 ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à

REM Method 3: ‡∏•‡∏≠‡∏á wheel version ‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£
echo.
echo üîÑ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: ‡∏•‡∏≠‡∏á version ‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£...
pip install llama-cpp-python==0.2.85 --only-binary=:all: --force-reinstall --no-cache-dir
if not errorlevel 1 (
    echo ‚úÖ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á version ‡πÄ‡∏Å‡πà‡∏≤‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!
    goto :test_installation
)

echo ‚ùå ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3 ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à

REM Method 4: ‡∏•‡∏≠‡∏á‡∏à‡∏≤‡∏Å alternative source
echo.
echo üîÑ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 4: ‡∏•‡∏≠‡∏á‡∏à‡∏≤‡∏Å alternative wheel source...
pip install --pre llama-cpp-python --extra-index-url https://test.pypi.org/simple/ --force-reinstall --no-cache-dir
if not errorlevel 1 (
    echo ‚úÖ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏à‡∏≤‡∏Å alternative source ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!
    goto :test_installation
)

echo ‚ùå ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 4 ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à

REM Method 5: ‡∏•‡∏≠‡∏á manual download wheel
echo.
echo üîÑ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 5: ‡∏•‡∏≠‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î wheel ‡πÅ‡∏ö‡∏ö manual...
echo üí° ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ compatible wheel...

python -c "^
import platform; ^
import sys; ^
print(f'Python version: {sys.version}'); ^
print(f'Platform: {platform.platform()}'); ^
print(f'Architecture: {platform.architecture()}'); ^
print(f'Machine: {platform.machine()}'); ^
try: ^
    from packaging.tags import sys_tags; ^
    tags = list(sys_tags()); ^
    print('Compatible wheel tags:'); ^
    for i, tag in enumerate(tags[:5]): ^
        print(f'  {tag}'); ^
    if len(tags) > 5: ^
        print(f'  ... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(tags)-5} tags'); ^
except ImportError: ^
    print('packaging module not available')^
"

echo.
echo ‚ùå ‡∏ó‡∏∏‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
goto :installation_failed

:test_installation
echo.
echo üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á...
python -c "
try:
    import llama_cpp
    print('‚úÖ Import llama_cpp ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à')
    print(f'üîß Version: {llama_cpp.__version__}')
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á instance (‡πÑ‡∏°‡πà‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•)
    print('üîÑ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Llama class...')
    # ‡πÑ‡∏°‡πà‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•
    print('‚úÖ llama-cpp-python ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!')
    
except ImportError as e:
    print(f'‚ùå Import ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}')
    exit(1)
except Exception as e:
    print(f'‚ö†Ô∏è Warning: {e}')
    print('‚úÖ llama-cpp-python ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏ï‡πà‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢')
"

if errorlevel 1 (
    echo ‚ùå ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô
    goto :installation_failed
)

echo.
echo üì¶ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies ‡∏≠‡∏∑‡πà‡∏ô‡πÜ...
pip install streamlit langchain langchain-community faiss-cpu sentence-transformers

echo.
echo üéâ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!
echo ===============
echo.
echo üìã ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ:
echo 1. ‡∏£‡∏±‡∏ô: streamlit run rag_chatbot.py
echo 2. ‡πÄ‡∏õ‡∏¥‡∏î browser: http://localhost:8501
echo 3. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û: .\issue\test_performance.bat
echo.
echo üí° ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö CPU-only
echo    ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ GPU ‡πÉ‡∏´‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Visual Studio Build Tools ‡∏Å‡πà‡∏≠‡∏ô
echo.

pause
exit /b 0

:installation_failed
echo.
echo ‚ùå ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
echo ==================
echo.
echo üîß ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:
echo.
echo 1Ô∏è‚É£ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Visual Studio Build Tools:
echo    winget install Microsoft.VisualStudio.2022.BuildTools
echo    ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏Å "C++ build tools" workload
echo.
echo 2Ô∏è‚É£ ‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á wheel manual:
echo    ‡πÑ‡∏õ‡∏ó‡∏µ‡πà https://github.com/abetlen/llama-cpp-python/releases
echo    ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î wheel ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Windows ‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢:
echo    pip install [‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå.whl]
echo.
echo 3Ô∏è‚É£ ‡πÉ‡∏ä‡πâ Docker:
echo    docker run -p 8501:8501 [llama-cpp-python-image]
echo.
echo 4Ô∏è‚É£ ‡πÉ‡∏ä‡πâ cloud service:
echo    - Google Colab
echo    - Hugging Face Spaces
echo    - Streamlit Cloud
echo.
echo 5Ô∏è‚É£ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á alternative:
echo    pip install ollama
echo    ‡∏´‡∏£‡∏∑‡∏≠ pip install transformers torch
echo.

pause
exit /b 1
