# Windows Setup Guide for LLM-RAG Chatbot
## ‡∏£‡∏∞‡∏ö‡∏ö RAG Chatbot ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ Local LLM ‡∏û‡∏£‡πâ‡∏≠‡∏° GPU acceleration ‡∏ö‡∏ô Windows

### ‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏£‡∏∞‡∏ö‡∏ö
- Windows 10/11 (64-bit)
- NVIDIA GPU (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ 8GB+ VRAM)
- Python 3.8+ 
- 16GB+ RAM
- 50GB+ ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤‡∏á

## üöÄ ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥) 

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡πÉ‡∏ä‡πâ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏ö‡∏ä‡∏∏‡∏î
```cmd
REM ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á Visual Studio)
install_complete_detailed.bat
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏¢‡∏Å‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô
```cmd
REM 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö
auto_setup_windows.bat

REM 2. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Python environment
setup_python_env_windows.bat

REM 3. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î models
download_models_windows.bat

REM 4. ‡∏£‡∏±‡∏ô application
run_app_windows.bat
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: Troubleshooting
```cmd
REM ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡πÉ‡∏ä‡πâ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢
diagnose_llama_cpp.bat
```

---

#### 1. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á NVIDIA CUDA Toolkit
```cmd
REM ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á CUDA Toolkit 12.x ‡∏à‡∏≤‡∏Å:
REM https://developer.nvidia.com/cuda-downloads

REM ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á
nvidia-smi
nvcc --version
```

#### 2. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Python
```cmd
REM ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Python 3.11 ‡∏à‡∏≤‡∏Å python.org
REM ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å "Add Python to PATH" ‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á

python --version
pip --version
```

#### 3. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Git ‡πÅ‡∏•‡∏∞ Build Tools
```cmd
REM ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á:
REM - Git for Windows: https://git-scm.com/download/win
REM - Visual Studio Build Tools: https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2022

git --version
```

#### 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á Python Virtual Environment
```cmd
REM ‡∏™‡∏£‡πâ‡∏≤‡∏á virtual environment
python -m venv llm_rag_env

REM ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Windows CMD)
llm_rag_env\Scripts\activate.bat

REM ‡∏´‡∏£‡∏∑‡∏≠ PowerShell
llm_rag_env\Scripts\Activate.ps1

REM ‡∏≠‡∏±‡∏û‡πÄ‡∏Å‡∏£‡∏î pip
python -m pip install --upgrade pip
```

#### 5. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Python Packages
```cmd
REM ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô virtual environment ‡∏Å‡πà‡∏≠‡∏ô
llm_rag_env\Scripts\activate.bat

REM ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏à‡∏≤‡∏Å requirements.txt
pip install -r requirements.txt

REM ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyTorch ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

REM ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á llama-cpp-python ‡∏û‡∏£‡πâ‡∏≠‡∏° CUDA support
set CMAKE_ARGS=-DLLAMA_CUBLAS=on
pip install llama-cpp-python==0.2.90 --no-cache-dir
```

#### 6. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Environment Variables (Optional)
```cmd
REM ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô System Environment Variables:
set CUDA_VISIBLE_DEVICES=0
set CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.1
```

#### 7. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î LLM Model
```cmd
REM ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö models
mkdir C:\AI\llm\Llama-3.2-3B-Instruct-GGUF
cd C:\AI\llm\Llama-3.2-3B-Instruct-GGUF

REM ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î model (‡πÉ‡∏ä‡πâ browser ‡∏´‡∏£‡∏∑‡∏≠ wget for Windows)
curl -L -o Llama-3.2-3B-Instruct-Q5_K_M.gguf https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q5_K_M.gguf
```

#### 8. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Embedding Model (Optional)
```cmd
mkdir C:\AI\embedding-models
cd C:\AI\embedding-models
git clone https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2
```

#### 9. ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Path ‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î
‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå `rag_chatbot.py` ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î 46:
```python
# ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å Linux path
llm_model = r"C:\AI\llm\Llama-3.2-3B-Instruct-GGUF\Llama-3.2-3B-Instruct-Q5_K_M.gguf"

# ‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç embedding path ‡∏î‡πâ‡∏ß‡∏¢ (‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î 20)
local_embed_path = r"C:\AI\embedding-models\all-MiniLM-L6-v2"
```

#### 10. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á
```cmd
REM ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô virtual environment
llm_rag_env\Scripts\activate.bat

REM ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô project directory
cd LLM-RAG

REM ‡∏£‡∏±‡∏ô Streamlit
streamlit run rag_chatbot.py
```

### ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ

#### ‡∏´‡∏≤‡∏Å llama-cpp-python ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å CUDA:
```cmd
pip uninstall llama-cpp-python
set CMAKE_ARGS=-DLLAMA_CUBLAS=on
pip install llama-cpp-python --no-cache-dir --force-reinstall
```

#### ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ Visual Studio Build Tools:
```cmd
REM ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Visual Studio Build Tools 2022
REM ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ conda ‡πÅ‡∏ó‡∏ô pip:
conda install -c conda-forge llama-cpp-python
```

#### ‡∏´‡∏≤‡∏Å CUDA ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô:
```cmd
REM ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö CUDA path
echo %CUDA_PATH%
echo %PATH%

REM ‡πÄ‡∏û‡∏¥‡πà‡∏° CUDA ‡πÉ‡∏ô PATH ‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
set PATH=%CUDA_PATH%\bin;%PATH%
```

#### ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ PowerShell Execution Policy:
```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

### Windows-specific Tips:

#### ‡πÉ‡∏ä‡πâ Conda ‡πÅ‡∏ó‡∏ô pip (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥):
```cmd
REM ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Miniconda
REM https://docs.conda.io/en/latest/miniconda.html

conda create -n llm_rag python=3.11
conda activate llm_rag
conda install -c conda-forge streamlit langchain faiss-cpu sentence-transformers
pip install llama-cpp-python --no-cache-dir
```

#### ‡πÉ‡∏ä‡πâ WSL2 (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Advanced Users):
```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á WSL2 ‡πÅ‡∏•‡∏∞ Ubuntu
# ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ Linux setup scripts
wsl --install Ubuntu
# ‡πÉ‡∏ä‡πâ auto_setup.sh ‡πÉ‡∏ô WSL
```

### Performance ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á (Windows):
- **CPU:** ~2,500 tokens/second
- **GPU:** ~3,800+ tokens/second
- **Memory Usage:** ~4-6GB VRAM ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 3B model

---

## üìÅ Model Paths ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Windows

### LLM Model:
```
Path: C:\AI\llm\Llama-3.2-3B-Instruct-GGUF\Llama-3.2-3B-Instruct-Q5_K_M.gguf
Size: ~2.16 GB
URL: https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q5_K_M.gguf
```

### Embedding Model (Optional):
```
Path: C:\AI\embedding-models\all-MiniLM-L6-v2
Size: ~90 MB
URL: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2
```
