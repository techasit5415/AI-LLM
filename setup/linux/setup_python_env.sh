#!/bin/bash

# Python Environment Setup Script for LLM-RAG
# ‡∏£‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á system dependencies ‡πÅ‡∏•‡πâ‡∏ß

set -e

echo "üêç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Python environment ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM-RAG..."

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô project directory
if [[ ! -f "requirements.txt" ]]; then
    echo "‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå requirements.txt"
    echo "   ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤ cd ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô LLM-RAG directory ‡∏Å‡πà‡∏≠‡∏ô"
    exit 1
fi

# ‡∏™‡∏£‡πâ‡∏≤‡∏á virtual environment
echo "üì¶ ‡∏™‡∏£‡πâ‡∏≤‡∏á virtual environment..."
if [[ ! -d "llm_rag_env" ]]; then
    python3 -m venv llm_rag_env
    echo "‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á virtual environment ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß"
else
    echo "‚ÑπÔ∏è virtual environment ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß"
fi

# ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô virtual environment
echo "üîÑ ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô virtual environment..."
source llm_rag_env/bin/activate

# ‡∏≠‡∏±‡∏û‡πÄ‡∏Å‡∏£‡∏î pip
echo "‚¨ÜÔ∏è ‡∏≠‡∏±‡∏û‡πÄ‡∏Å‡∏£‡∏î pip..."
pip install --upgrade pip

# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á basic packages ‡∏Å‡πà‡∏≠‡∏ô
echo "üì¶ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á basic packages..."
pip install wheel setuptools

# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyTorch ‡∏Å‡πà‡∏≠‡∏ô (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á conflict)
echo "üî• ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyTorch..."
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á packages ‡∏≠‡∏∑‡πà‡∏ô‡πÜ
echo "üì¶ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á packages ‡∏à‡∏≤‡∏Å requirements.txt..."
pip install streamlit==1.29.0
pip install langchain==0.1.0 langchain-community==0.0.10
pip install faiss-cpu==1.7.4
pip install sentence-transformers==2.2.2
pip install pypdf==3.17.4 python-docx==1.1.0
pip install tiktoken==0.5.2
pip install numpy==1.24.3 pandas==2.0.3
pip install requests==2.31.0 beautifulsoup4==4.12.2 lxml==4.9.3
pip install Pillow==10.1.0 python-dotenv==1.0.0

# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á llama-cpp-python ‡∏û‡∏£‡πâ‡∏≠‡∏° CUDA support
echo "ü¶ô ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á llama-cpp-python ‡∏û‡∏£‡πâ‡∏≠‡∏° CUDA support..."
pip uninstall -y llama-cpp-python || true
CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip install llama-cpp-python==0.2.90 --no-cache-dir

echo "‚úÖ Python environment setup ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!"
echo ""
echo "üìã ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ:"
echo "1. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î LLM model:"
echo "   cd ~/Documents/AI/llm/Llama-3.2-3B-Instruct-GGUF"
echo "   wget https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q5_K_M.gguf"
echo ""
echo "2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå rag_chatbot.py (‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î 46)"
echo ""
echo "3. ‡∏£‡∏±‡∏ô application:"
echo "   source llm_rag_env/bin/activate  # ‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"
echo "   streamlit run rag_chatbot.py"
echo ""
echo "üéâ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!"
