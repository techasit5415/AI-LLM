# Windows Setup - Quick Start Guide
## ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πà‡∏ß‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Windows

### ‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
- Windows 10/11 (64-bit)
- NVIDIA GPU ‡∏û‡∏£‡πâ‡∏≠‡∏° driver
- Python 3.8+
- Git for Windows

---

## ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥

### 1. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Prerequisites
```cmd
REM ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏¥‡πà‡∏á‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏Å‡πà‡∏≠‡∏ô:
REM 1. Python ‡∏à‡∏≤‡∏Å python.org (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å "Add to PATH")
REM 2. Git for Windows ‡∏à‡∏≤‡∏Å git-scm.com  
REM 3. NVIDIA CUDA Toolkit ‡∏à‡∏≤‡∏Å developer.nvidia.com
REM 4. Visual Studio Build Tools (optional ‡πÅ‡∏ï‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
```

### 2. ‡∏£‡∏±‡∏ô Setup Scripts
```cmd
REM Copy ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå LLM-RAG ‡∏°‡∏≤‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á Windows
cd LLM-RAG

REM 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö
auto_setup_windows.bat

REM 2. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Python environment
setup_python_env_windows.bat

REM 3. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î models
download_models_windows.bat

REM 4. ‡∏£‡∏±‡∏ô application
run_app_windows.bat
```

---

## ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö Manual

### 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Virtual Environment
```cmd
python -m venv llm_rag_env
llm_rag_env\Scripts\activate.bat
python -m pip install --upgrade pip
```

### 2. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Packages
```cmd
REM ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyTorch ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

REM ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á packages ‡∏≠‡∏∑‡πà‡∏ô‡πÜ
pip install streamlit langchain langchain-community faiss-cpu sentence-transformers
pip install pypdf python-docx tiktoken numpy pandas requests beautifulsoup4 lxml Pillow python-dotenv

REM ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á llama-cpp-python ‡∏û‡∏£‡πâ‡∏≠‡∏° CUDA
set CMAKE_ARGS=-DLLAMA_CUBLAS=on
pip install llama-cpp-python==0.2.90 --no-cache-dir
```

### 3. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Models
```cmd
REM ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
mkdir C:\AI\llm\Llama-3.2-3B-Instruct-GGUF
cd C:\AI\llm\Llama-3.2-3B-Instruct-GGUF

REM ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î LLM model
curl -L -o Llama-3.2-3B-Instruct-Q5_K_M.gguf https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q5_K_M.gguf
```

### 4. ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Path ‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î
‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå `rag_chatbot.py`:

**‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î 46:**
```python
# ‡∏à‡∏≤‡∏Å
llm_model = "/home/techasit/Documents/AI/llm/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct-Q5_K_M.gguf"

# ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô
llm_model = r"C:\AI\llm\Llama-3.2-3B-Instruct-GGUF\Llama-3.2-3B-Instruct-Q5_K_M.gguf"
```

**‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î 20:**
```python
# ‡∏à‡∏≤‡∏Å  
local_embed_path = "/home/techasit/Documents/AI/embedding-models/all-MiniLM-L6-v2"

# ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô
local_embed_path = r"C:\AI\embedding-models\all-MiniLM-L6-v2"
```

### 5. ‡∏£‡∏±‡∏ô Application
```cmd
llm_rag_env\Scripts\activate.bat
streamlit run rag_chatbot.py
```

---

## Troubleshooting Windows

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ CUDA ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô:
```cmd
REM ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö CUDA
nvidia-smi
nvcc --version

REM ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ environment variables
set CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.1
set PATH=%CUDA_PATH%\bin;%PATH%
```

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ llama-cpp-python:
```cmd
REM ‡∏•‡∏ö‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏´‡∏°‡πà
pip uninstall llama-cpp-python
set CMAKE_ARGS=-DLLAMA_CUBLAS=on
pip install llama-cpp-python --no-cache-dir --force-reinstall
```

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ PowerShell Execution Policy:
```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Build Tools:
```cmd
REM ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Visual Studio Build Tools 2022
REM ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ conda:
conda install -c conda-forge llama-cpp-python
```

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Models:
```cmd
REM ‡∏ñ‡πâ‡∏≤ curl ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ‡πÉ‡∏ä‡πâ PowerShell:
powershell -Command "Invoke-WebRequest -Uri 'https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q5_K_M.gguf' -OutFile 'Llama-3.2-3B-Instruct-Q5_K_M.gguf'"

REM ‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡πà‡∏≤‡∏ô browser ‡πÅ‡∏•‡πâ‡∏ß copy ‡∏°‡∏≤‡πÉ‡∏™‡πà folder: C:\AI\llm\Llama-3.2-3B-Instruct-GGUF\
```

---

## üìÅ Model Paths for Windows

### LLM Model:
```
Path: C:\AI\llm\Llama-3.2-3B-Instruct-GGUF\Llama-3.2-3B-Instruct-Q5_K_M.gguf
Size: ~2.16 GB
```

### Embedding Model (Optional):
```
Path: C:\AI\embedding-models\all-MiniLM-L6-v2
Size: ~90 MB
```

---

## Files ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á Copy ‡πÑ‡∏õ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á Windows

### Core Files:
```
LLM-RAG\
‚îú‚îÄ‚îÄ rag_chatbot.py              # Main app (‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ path)
‚îú‚îÄ‚îÄ pages\backend\rag_functions.py  # Backend functions  
‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îú‚îÄ‚îÄ vector store\              # Pre-built vector databases
‚îÇ   ‚îú‚îÄ‚îÄ naruto\
‚îÇ   ‚îú‚îÄ‚îÄ snake\
‚îÇ   ‚îî‚îÄ‚îÄ naruto_snake\
‚îî‚îÄ‚îÄ data sources\              # Source documents
    ‚îú‚îÄ‚îÄ wikipedia_naruto.txt
    ‚îî‚îÄ‚îÄ wikipedia_snake.txt
```

### Windows Setup Scripts:
```
‚îú‚îÄ‚îÄ auto_setup_windows.bat          # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö
‚îú‚îÄ‚îÄ setup_python_env_windows.bat    # ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Python env
‚îú‚îÄ‚îÄ download_models_windows.bat     # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î models
‚îú‚îÄ‚îÄ run_app_windows.bat             # ‡∏£‡∏±‡∏ô application
‚îú‚îÄ‚îÄ WINDOWS_SETUP.md                # ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡πÄ‡∏ï‡πá‡∏°
‚îî‚îÄ‚îÄ WINDOWS_QUICK_START.md          # ‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ
```

---

## Expected Performance (Windows)
- **RTX 4060:** ~3,800 tokens/second  
- **RTX 3060:** ~3,300 tokens/second
- **GTX 1660:** ~2,800 tokens/second
- **CPU only:** ~2,500 tokens/second

---

## Tips ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Windows

1. **‡πÉ‡∏ä‡πâ Command Prompt** ‡πÅ‡∏ó‡∏ô PowerShell ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤
2. **‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Conda** ‡∏ñ‡πâ‡∏≤ pip ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤
3. **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Antivirus** ‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà block Python scripts
4. **‡πÉ‡∏ä‡πâ WSL2** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö advanced users ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Linux environment
