@echo off
chcp 65001 >nul
REM CPU-only setup script for llama-cpp-python
REM ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö CPU-only ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö llama-cpp-python

echo üíª Setup llama-cpp-python ‡πÅ‡∏ö‡∏ö CPU-only ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Windows
echo =========================================================

REM ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô project directory
cd /d "%~dp0.."
if not exist "rag_chatbot.py" (
    echo ‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå rag_chatbot.py
    echo    ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤ cd ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô LLM-RAG directory ‡∏Å‡πà‡∏≠‡∏ô
    pause
    exit /b 1
)

echo üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Prerequisites...

REM ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Python
python --version >nul 2>&1
if errorlevel 1 (
    echo ‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö Python
    echo    ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Python 3.8+ ‡∏à‡∏≤‡∏Å https://python.org
    pause
    exit /b 1
) else (
    for /f "tokens=2" %%v in ('python --version 2^>^&1') do echo ‚úÖ Python %%v
)

REM ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Virtual Environment
if not exist "llm_rag_env" (
    echo üì¶ ‡∏™‡∏£‡πâ‡∏≤‡∏á Python virtual environment...
    python -m venv llm_rag_env
    if errorlevel 1 (
        echo ‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á virtual environment ‡πÑ‡∏î‡πâ
        pause
        exit /b 1
    )
) else (
    echo ‚úÖ ‡∏û‡∏ö virtual environment ‡πÅ‡∏•‡πâ‡∏ß
)

echo üîÑ ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô virtual environment...
call llm_rag_env\Scripts\activate.bat

REM ‡∏≠‡∏±‡∏û‡πÄ‡∏Å‡∏£‡∏î pip
echo üì¶ ‡∏≠‡∏±‡∏û‡πÄ‡∏Å‡∏£‡∏î pip...
python -m pip install --upgrade pip

REM ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
echo üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á llama-cpp-python ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô...
python -c "import llama_cpp; print('‚úÖ ‡∏û‡∏ö llama-cpp-python version:', llama_cpp.__version__)" 2>nul
if not errorlevel 1 (
    echo.
    echo ü§î ‡∏û‡∏ö llama-cpp-python ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡πâ‡∏ß
    set /p reinstall="‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏ö‡∏ö CPU-only ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà? (y/n): "
    if /i not "%reinstall%"=="y" (
        echo ‚è≠Ô∏è ‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á llama-cpp-python
        goto :install_other_packages
    )
    
    echo üóëÔ∏è ‡∏•‡∏ö version ‡πÄ‡∏Å‡πà‡∏≤...
    pip uninstall llama-cpp-python -y
)

echo üíª ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á llama-cpp-python ‡πÅ‡∏ö‡∏ö CPU-only...
echo.
echo ‚ö†Ô∏è ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: 
echo    - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Visual Studio Build Tools
echo    - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏à‡∏∞‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡πÅ‡∏ö‡∏ö GPU ‡πÅ‡∏ï‡πà‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Å‡∏ß‡πà‡∏≤
echo    - ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏û‡∏±‡∏í‡∏ô‡∏≤
echo.

REM ‡∏•‡∏≠‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö
echo üîÑ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏à‡∏≤‡∏Å PyPI standard...
pip install llama-cpp-python==0.2.90 --no-cache-dir

if errorlevel 1 (
    echo ‚ùå ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1 ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
    echo.
    echo üîÑ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏à‡∏≤‡∏Å pre-compiled wheel...
    pip install --pre llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu
    
    if errorlevel 1 (
        echo ‚ùå ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2 ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
        echo.
        echo üîÑ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö basic...
        pip install llama-cpp-python --no-deps --no-cache-dir
        
        if errorlevel 1 (
            echo ‚ùå ‡∏ó‡∏∏‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
            goto :installation_failed
        )
    )
)

echo ‚úÖ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á llama-cpp-python ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!

REM ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á
echo üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö llama-cpp-python...
python -c "from llama_cpp import Llama; print('‚úÖ llama-cpp-python ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à')" 2>nul
if errorlevel 1 (
    echo ‚ùå ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á
    echo üí° ‡∏•‡∏≠‡∏á‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π error:
    echo    python -c "from llama_cpp import Llama"
    goto :installation_failed
) else (
    echo ‚úÖ llama-cpp-python ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!
)

:install_other_packages
REM ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á packages ‡∏≠‡∏∑‡πà‡∏ô‡πÜ
echo üì¶ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á packages ‡∏≠‡∏∑‡πà‡∏ô‡πÜ...
pip install streamlit langchain langchain-community faiss-cpu sentence-transformers

echo.
echo üéâ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö CPU-only ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!
echo ==================================
echo.
echo üìã ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ:
echo 1. ‡∏£‡∏±‡∏ô application: streamlit run rag_chatbot.py
echo 2. ‡πÄ‡∏õ‡∏¥‡∏î browser ‡πÑ‡∏õ‡∏ó‡∏µ‡πà: http://localhost:8501
echo 3. ‡∏Å‡∏î "Create chatbot" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
echo 4. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö performance:
echo    - CPU mode: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß ~2000-2500 tokens/sec
echo    - Memory usage: ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 4-8 GB RAM
echo.
echo üí° ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô GPU ‡πÉ‡∏ô‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á
echo    ‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô .\issue\setup_complete_gpu.bat ‡πÅ‡∏ó‡∏ô
echo.

pause
exit /b 0

:installation_failed
echo.
echo ‚ùå ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
echo ==================
echo.
echo üîß ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:
echo.
echo 1Ô∏è‚É£ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Python ‡πÅ‡∏•‡∏∞ pip:
echo    python --version
echo    pip --version
echo.
echo 2Ô∏è‚É£ ‡∏≠‡∏±‡∏û‡πÄ‡∏Å‡∏£‡∏î pip ‡πÅ‡∏•‡∏∞ setuptools:
echo    python -m pip install --upgrade pip setuptools wheel
echo.
echo 3Ô∏è‚É£ ‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö minimal:
echo    pip install llama-cpp-python --no-deps
echo.
echo 4Ô∏è‚É£ ‡∏£‡∏±‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢:
echo    .\issue\diagnose_llama_cpp.bat
echo.
echo 5Ô∏è‚É£ ‡∏î‡∏π troubleshooting guide:
echo    .\issue\LLAMA_CPP_PYTHON_TROUBLESHOOTING.md
echo.

pause
exit /b 1
