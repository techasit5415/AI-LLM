# LLM-RAG Chatbot Setup Guide
## ‡∏£‡∏∞‡∏ö‡∏ö RAG Chatbot ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ Local LLM ‡∏û‡∏£‡πâ‡∏≠‡∏° GPU acceleration

### ‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏£‡∏∞‡∏ö‡∏ö
- Ubuntu/Debian Linux
- NVIDIA GPU (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ 8GB+ VRAM)
- Python 3.8+
- 16GB+ RAM
- 50GB+ ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤‡∏á

### ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô

#### 1. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á System Dependencies
```bash
# ‡πÉ‡∏´‡πâ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô script
chmod +x install_system_deps.sh
./install_system_deps.sh

# ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:
sudo apt update
sudo apt install -y nvidia-cuda-toolkit build-essential cmake git wget curl
sudo apt install -y python3-dev python3-pip python3-venv
sudo apt install -y libblas-dev liblapack-dev libopenblas-dev gfortran
sudo apt install -y libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1
sudo apt install -y poppler-utils ffmpeg libsndfile1
sudo apt install -y htop tree unzip
```

#### 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö NVIDIA Driver ‡πÅ‡∏•‡∏∞ CUDA
```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU
nvidia-smi

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö CUDA
nvcc --version

# ‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ NVIDIA Driver
sudo apt install -y nvidia-driver-535
sudo reboot
```

#### 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Python Virtual Environment
```bash
# ‡∏™‡∏£‡πâ‡∏≤‡∏á virtual environment
python3 -m venv llm_rag_env

# ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
source llm_rag_env/bin/activate

# ‡∏≠‡∏±‡∏û‡πÄ‡∏Å‡∏£‡∏î pip
pip install --upgrade pip
```

#### 4. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Python Packages
```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏à‡∏≤‡∏Å requirements.txt
pip install -r requirements.txt

# ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡∏•‡∏∞ package ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤:
pip install streamlit==1.29.0
pip install langchain==0.1.0 langchain-community==0.0.10
pip install faiss-cpu==1.7.4
pip install sentence-transformers==2.2.2
pip install pypdf==3.17.4
pip install numpy pandas torch torchvision torchaudio
pip install requests beautifulsoup4 lxml Pillow python-dotenv

# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á llama-cpp-python ‡∏û‡∏£‡πâ‡∏≠‡∏° CUDA support
CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip install llama-cpp-python==0.2.90
```

#### 5. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Environment Variables
```bash
# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô ~/.bashrc
echo 'export CUDA_VISIBLE_DEVICES=0' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH="/usr/local/cuda/lib64:$LD_LIBRARY_PATH"' >> ~/.bashrc
source ~/.bashrc
```

#### 6. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î LLM Model
```bash
# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö models
mkdir -p /home/$(whoami)/Documents/AI/llm/Llama-3.2-3B-Instruct-GGUF

# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Llama 3.2 3B Instruct GGUF
cd /home/$(whoami)/Documents/AI/llm/Llama-3.2-3B-Instruct-GGUF
wget https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q5_K_M.gguf

# LLM path: /home/$(whoami)/Documents/AI/llm/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct-Q5_K_M.gguf
```

#### 7. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Embedding Model (Optional)
```bash
# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î embedding model ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ offline
mkdir -p /home/$(whoami)/Documents/AI/embedding-models
cd /home/$(whoami)/Documents/AI/embedding-models
git clone https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2

# Embedding path: /home/$(whoami)/Documents/AI/embedding-models/all-MiniLM-L6-v2
```

#### 8. Setup Project
```bash
# Clone ‡∏´‡∏£‡∏∑‡∏≠ copy ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ LLM-RAG
git clone <repository-url> LLM-RAG
cd LLM-RAG

# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç path ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå rag_chatbot.py (‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î 46)
# ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô path ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà
```

#### 9. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á
```bash
# ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô virtual environment
source llm_rag_env/bin/activate

# ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô project directory
cd LLM-RAG

# ‡∏£‡∏±‡∏ô Streamlit
streamlit run rag_chatbot.py
```

### ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ

#### ‡∏´‡∏≤‡∏Å llama-cpp-python ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å CUDA:
```bash
pip uninstall llama-cpp-python
CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip install llama-cpp-python --no-cache-dir
```

#### ‡∏´‡∏≤‡∏Å CUDA ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô:
```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö CUDA path
export CUDA_HOME=/usr/local/cuda
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
```

#### ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ torch:
```bash
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Structure ‡∏Ç‡∏≠‡∏á Project ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ:
```
LLM-RAG/
‚îú‚îÄ‚îÄ rag_chatbot.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ install_system_deps.sh
‚îú‚îÄ‚îÄ README.md (‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ)
‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îî‚îÄ‚îÄ backend/
‚îÇ       ‚îî‚îÄ‚îÄ rag_functions.py
‚îú‚îÄ‚îÄ vector store/
‚îÇ   ‚îú‚îÄ‚îÄ naruto/
‚îÇ   ‚îú‚îÄ‚îÄ snake/
‚îÇ   ‚îî‚îÄ‚îÄ naruto_snake/
‚îî‚îÄ‚îÄ data sources/
    ‚îú‚îÄ‚îÄ wikipedia_naruto.txt
    ‚îî‚îÄ‚îÄ wikipedia_snake.txt
```

### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:
1. ‡πÄ‡∏õ‡∏¥‡∏î browser ‡πÑ‡∏õ‡∏ó‡∏µ‡πà `http://localhost:8501`
2. ‡∏Å‡∏î "Create chatbot" 
3. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Vector Store ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
4. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°!

### Performance ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á:
- **CPU:** ~2,700 tokens/second
- **GPU:** ~4,000+ tokens/second
- **Memory Usage:** ~4-6GB VRAM ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 3B model

---

## üìÅ Model Paths ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Linux

### LLM Model:
```
Path: ~/Documents/AI/llm/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct-Q5_K_M.gguf
Full Path: /home/$(whoami)/Documents/AI/llm/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct-Q5_K_M.gguf
Size: ~2.16 GB
URL: https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q5_K_M.gguf
```

### Embedding Model (Optional):
```
Path: ~/Documents/AI/embedding-models/all-MiniLM-L6-v2
Full Path: /home/$(whoami)/Documents/AI/embedding-models/all-MiniLM-L6-v2
Size: ~90 MB
URL: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2
```
