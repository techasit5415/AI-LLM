#!/bin/bash

# Linux Run Application Script
# ‡∏£‡∏±‡∏ô LLM-RAG Chatbot ‡∏ö‡∏ô Linux

echo "üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô LLM-RAG Chatbot ‡∏ö‡∏ô Linux..."

# ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ‡∏¢‡∏±‡∏á project directory
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(cd "$SCRIPT_DIR/../.." && pwd)"
cd "$PROJECT_DIR"

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô project directory
if [[ ! -f "rag_chatbot.py" ]]; then
    echo "‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå rag_chatbot.py ‡πÉ‡∏ô $PROJECT_DIR"
    echo "   ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path ‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Å‡∏ï‡πå"
    exit 1
fi

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö virtual environment
if [[ ! -d "llm_rag_env" ]]; then
    echo "‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö virtual environment"
    echo "   ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô setup/linux/setup_python_env.sh ‡∏Å‡πà‡∏≠‡∏ô"
    exit 1
fi

# ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô virtual environment
echo "üîÑ ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô virtual environment..."
source llm_rag_env/bin/activate

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö LLM model
MODEL_PATH="$HOME/Documents/AI/llm/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct-Q5_K_M.gguf"
if [[ ! -f "$MODEL_PATH" ]]; then
    echo "‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö LLM model ‡∏ó‡∏µ‡πà: $MODEL_PATH"
    echo "   ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô setup/linux/download_models.sh ‡∏Å‡πà‡∏≠‡∏ô"
    exit 1
fi

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ environment variables
export CUDA_VISIBLE_DEVICES=0
export LD_LIBRARY_PATH="/usr/local/cuda/lib64:$LD_LIBRARY_PATH"

# ‡∏£‡∏±‡∏ô Streamlit
echo "üåü ‡πÄ‡∏õ‡∏¥‡∏î Streamlit application..."
echo "üì± ‡πÄ‡∏õ‡∏¥‡∏î browser ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏õ‡∏ó‡∏µ‡πà: http://localhost:8501"
echo "üõë ‡∏Å‡∏î Ctrl+C ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô"
echo ""

streamlit run rag_chatbot.py

echo ""
echo "üèÅ ‡∏õ‡∏¥‡∏î LLM-RAG Chatbot ‡πÅ‡∏•‡πâ‡∏ß"
